# Public_026

# Neural network l√† g√¨

Con ch√≥ c√≥ th·ªÉ ph√¢n bi·ªát ƒë∆∞·ª£c ng∆∞·ªùi th√¢n trong gia ƒë√¨nh v√† ng∆∞·ªùi l·∫° hay ƒë·ª©a tr·∫ª c√≥ th·ªÉ ph√¢n bi·ªát ƒë∆∞·ª£c c√°c con v·∫≠t. Nh·ªØng vi·ªác t∆∞·ªüng ch·ª´ng nh∆∞ r·∫•t ƒë∆°n gi·∫£n nh∆∞ng l·∫°i c·ª±c k√¨ kh√≥ ƒë·ªÉ th·ª±c hi·ªán b·∫±ng m√°y t√≠nh. V·∫≠y s·ª± kh√°c bi·ªát n·∫±m ·ªü ƒë√¢u? C√¢u tr·∫£ l·ªùi n·∫±m ·ªü c·∫•u tr√∫c b·ªô n√£o v·ªõi l∆∞·ª£ng l·ªõn c√°c n∆°-ron th·∫ßn kinh li√™n k·∫øt v·ªõi nhau. Li·ªáu m√°y t√≠nh c√≥ th·ªÉ m√¥ ph·ªèng l·∫°i c·∫•u tr√∫c b·ªô n√£o ƒë·ªÉ gi·∫£i c√°c b√†i to√°n tr√™n ???

Neural l√† t√≠nh t·ª´ c·ªßa neuron (n∆°-ron), network ch·ªâ c·∫•u tr√∫c, c√°ch c√°c n∆°-ron ƒë√≥ li√™n k·∫øt v·ªõi nhau, n√™n neural network (NN) l√† m·ªôt h·ªá th·ªëng t√≠nh to√°n l·∫•y c·∫£m h·ª©ng t·ª´ s·ª± ho·∫°t ƒë·ªông c·ªßa c√°c n∆°-ron trong h·ªá th·∫ßn kinh.

## Ho·∫°t ƒë·ªông c·ªßa c√°c n∆°-ron

N∆°-ron l√† ƒë∆°n v·ªã c∆° b·∫£n c·∫•u t·∫°o h·ªá th·ªëng th·∫ßn kinh v√† l√† th√†nh ph·∫ßn quan tr·ªçng nh·∫•t c·ªßa n√£o. ƒê·∫ßu ch√∫ng ta g·ªìm kho·∫£ng 10 tri·ªáu n∆°-ron v√† m·ªói n∆°-ron l·∫°i li√™n k·∫øt v·ªõi t·∫ßm

## n∆°-ron kh√°c.

| ·ªû m·ªói n∆°-ron c√≥ ph·∫ßn th√¢n (soma) ch·ª©a nh√¢n, c√°c t√≠n hi·ªáu ƒë·∫ßu v√†o qua s·ª£i nh√°nh | (dendrites) v√† c√°c t√≠n hi·ªáu ƒë·∫ßu ra qua s·ª£i tr·ª•c (axon) k·∫øt n·ªëi v·ªõi c√°c n∆°-ron kh√°c. Hi·ªÉu |
| --- | --- |
| ƒë∆°n gi·∫£n m·ªói n∆°-ron nh·∫≠n d·ªØ li·ªáu ƒë·∫ßu v√†o qua s·ª£i nh√°nh v√† truy·ªÅn d·ªØ li·ªáu ƒë·∫ßu ra qua | s·ª£i tr·ª•c, ƒë·∫øn c√°c s·ª£i nh√°nh c·ªßa c√°c n∆°-ron kh√°c. |

M·ªói n∆°-ron nh·∫≠n xung ƒëi·ªán t·ª´ c√°c n∆°-ron kh√°c qua s·ª£i nh√°nh. N·∫øu c√°c xung ƒëi·ªán n√†y ƒë·ªß l·ªõn ƒë·ªÉ k√≠ch ho·∫°t n∆°-ron, th√¨ t√≠n hi·ªáu n√†y ƒëi qua s·ª£i tr·ª•c ƒë·∫øn c√°c s·ª£i nh√°nh c·ªßa c√°c n∆°-ron kh√°c.

![]({"images/image1.png"})

H√¨nh 5.1: T·∫ø b√†o th·∫ßn kinh [14]

=> ·ªû m·ªói n∆°-ron c·∫ßn quy·∫øt ƒë·ªãnh c√≥ k√≠ch ho·∫°t n∆°-ron ƒë·∫•y hay kh√¥ng. T∆∞∆°ng t·ª± c√°c ho·∫°t ƒë·ªông c·ªßa h√†m sigmoid b√†i tr∆∞·ªõc.

Tuy nhi√™n NN ch·ªâ l√† l·∫•y c·∫£m h·ª©ng t·ª´ n√£o b·ªô v√† c√°ch n√≥ ho·∫°t ƒë·ªông, ch·ª© kh√¥ng ph·∫£i b·∫Øt ch∆∞·ªõc to√†n b·ªô c√°c ch·ª©c nƒÉng c·ªßa n√≥. Vi·ªác ch√≠nh c·ªßa ch√∫ng ta l√† d√πng m√¥ h√¨nh ƒë·∫•y ƒëi gi·∫£i quy·∫øt c√°c b√†i to√°n ch√∫ng ta c·∫ßn.

# M√¥ h√¨nh neural network

## Logistic regression

Logistic regression l√† m√¥ h√¨nh neural network ƒë∆°n gi·∫£n nh·∫•t ch·ªâ v·ªõi input layer v√† output layer.

M√¥ h√¨nh c·ªßa logistic regression t·ª´ b√†i tr∆∞·ªõc l√†: _y_ÀÜ=_œÉ_(_w_0+_w_1‚àó_x_1+_w_2‚àó_x_2). C√≥ 2 b∆∞·ªõc:

T√≠nh t·ªïng linear: _z _=1‚àó_w_0+_x_1‚àó_w_1+_x_2‚àó_w_2

√Åp d·ª•ng sigmoid function: _y_ÀÜ=_œÉ_(_z_)

ƒê·ªÉ bi·ªÉu di·ªÖn g·ªçn l·∫°i ta s·∫Ω g·ªôp hai b∆∞·ªõc tr√™n th√†nh m·ªôt tr√™n bi·ªÉu ƒë·ªì nh∆∞ h√¨nh 5.2.

![]({"images/image2.png"})

H√¨nh 5.2: M√¥ h√¨nh logistic regression

H·ªá s·ªë _w_0 ƒë∆∞·ª£c g·ªçi l√† bias. ƒê·ªÉ √Ω t·ª´ nh·ªØng b√†i tr∆∞·ªõc ƒë·∫øn gi·ªù d·ªØ li·ªáu khi t√≠nh to√°n lu√¥n ƒë∆∞·ª£c th√™m 1 ƒë·ªÉ t√≠nh h·ªá s·ªë bias _w_0 . T·∫°i sao l·∫°i c·∫ßn h·ªá s·ªë bias? Quay l·∫°i v·ªõi b√†i 1, ph∆∞∆°ng tr√¨nh ƒë∆∞·ªùng th·∫≥ng s·∫Ω th·∫ø n√†o n·∫øu b·ªè _w_0, ph∆∞∆°ng tr√¨nh gi·ªù c√≥ d·∫°ng: _y _= _w_1‚àó_x_, s·∫Ω lu√¥n ƒëi qua g·ªëc t·ªça ƒë·ªô v√† n√≥ kh√¥ng t·ªïng qu√°t h√≥a ph∆∞∆°ng tr√¨nh ƒë∆∞·ªùng th·∫≥ng n√™n c√≥ th·ªÉ kh√¥ng t√¨m ƒë∆∞·ª£c ph∆∞∆°ng tr√¨nh mong mu·ªën. => Vi·ªác th√™m bias (h·ªá s·ªë t·ª± do) l√† r·∫•t quan tr·ªçng.

H√†m sigmoid ·ªü ƒë√¢y ƒë∆∞·ª£c g·ªçi l√† activation function.

## M√¥ h√¨nh t·ªïng qu√°t

Layer ƒë·∫ßu ti√™n l√† input layer, c√°c layer ·ªü gi·ªØa ƒë∆∞·ª£c g·ªçi l√† hidden layer, layer cu·ªëi c√πng ƒë∆∞·ª£c g·ªçi l√† output layer. C√°c h√¨nh tr√≤n ƒë∆∞·ª£c g·ªçi l√† node.

M·ªói m√¥ h√¨nh lu√¥n c√≥ 1 input layer, 1 output layer, c√≥ th·ªÉ c√≥ ho·∫∑c kh√¥ng c√°c hidden layer. T·ªïng s·ªë layer trong m√¥ h√¨nh ƒë∆∞·ª£c quy ∆∞·ªõc l√† s·ªë layer - 1 (kh√¥ng t√≠nh input layer).

V√≠ d·ª• nh∆∞ ·ªü h√¨nh tr√™n c√≥ 1 input layer, 2 hidden layer v√† 1 output layer. S·ªë l∆∞·ª£ng layer c·ªßa m√¥ h√¨nh l√† 3 layer.

M·ªói node trong hidden layer v√† output layer :

Li√™n k·∫øt v·ªõi t·∫•t c·∫£ c√°c node ·ªü layer tr∆∞·ªõc ƒë√≥ v·ªõi c√°c h·ªá s·ªë w ri√™ng.

M·ªói node c√≥ 1 h·ªá s·ªë bias b ri√™ng.

Di·ªÖn ra 2 b∆∞·ªõc: t√≠nh t·ªïng linear v√† √°p d·ª•ng activation function.

## K√≠ hi·ªáu

S·ªë node trong hidden layer th·ª© i l√† _l_(_i_).

Ma tr·∫≠n _W_(_k_) k√≠ch th∆∞·ªõc _l_(_k_‚àí1) ‚àó_l_(_k_) l√† ma tr·∫≠n h·ªá s·ªë gi·ªØa layer (k-1) v√† layer k, trong ƒë√≥ _w_(_ij__k_) l√† h·ªá s·ªë k·∫øt n·ªëi t·ª´ node th·ª© i c·ªßa layer k-1 ƒë·∫øn node th·ª© j c·ªßa layer k.

![]({"images/image3.png"})

H√¨nh 5.3: M√¥ h√¨nh neural network

Vector ùëè(ùëò) k√≠ch th∆∞·ªõc ùëôùëò‚àó1 l√† h·ªá s·ªë bias c·ªßa c√°c node trong layer k, trong ƒë√≥ _b_(_i__k_) l√† bias c·ªßa node th·ª© i trong layer k.

(_l_)

V·ªõi node th·ª© i trong layer l c√≥ bias _b__i__(l)_

th·ª±c hi·ªán 2 b∆∞·ªõc:

* T√≠nh t·ªïng t·∫•t c·∫£ c√°c node trong layer tr∆∞·ªõc nh√¢n v·ªõi h·ªá s·ªë w t∆∞∆°ng ·ª©ng, r·ªìi

c·ªông v·ªõi bias b.

√Åp d·ª•ng activation function: _a__i__(l)_ =_œÉ_(_z__i __(l)_)

Vector _z_(_k_) k√≠ch th∆∞·ªõc _l_(_k_) ‚àó1 l√† gi√° tr·ªã c√°c node trong layer k sau b∆∞·ªõc t√≠nh t·ªïng linear.

Vector _a_(_k_) k√≠ch th∆∞·ªõc _l_(_k_) ‚àó1 l√† gi√° tr·ªã c·ªßa c√°c node trong layer k sau khi √°p d·ª•ng h√†m activation function.

M√¥ h√¨nh neural network tr√™n g·ªìm 3 layer. Input layer c√≥ 2 node (_l_(0) =2), hidden layer 1 c√≥ 3 node, hidden layer 2 c√≥ 3 node v√† output layer c√≥ 1 node.

Do m·ªói node trong hidden layer v√† output layer ƒë·ªÅu c√≥ bias n√™n trong input layer v√† hidden layer c·∫ßn th√™m node 1 ƒë·ªÉ t√≠nh bias (nh∆∞ng kh√¥ng t√≠nh v√†o t·ªïng s·ªë node layer c√≥).

# Feedforward

ƒê·ªÉ nh·∫•t qu√°n v·ªÅ m·∫∑t k√Ω hi·ªáu, g·ªçi input layer l√† _a_(0)(= _x_) k√≠ch th∆∞·ªõc 2*1.

T∆∞∆°ng t·ª± ta c√≥:

_z_(2) =(_W_(2))_T _‚àó_a_(1) +_b_(2)

_a_(2) =_œÉ_(_z_(2))

_z_(3) =(_W_(3))_T _‚àó_a_(2) +_b_(3)

![]({"images/image4.png"})
![]({"images/image5.png"})

| A | NOT(A) |
| --- | --- |
| 0 | 1 |
| 1 | 0 |

| A | B | A AND B |
| --- | --- | --- |
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

| A | B | A OR B |
| --- | --- | --- |
| 0 | 0 | 0 |
| 0 | 1 | 1 |

_y_ÀÜ= _a_(3) =_œÉ_(_z_(3))

![]({"images/image6.png"})

H√¨nh 5.4: Feedforward

# Logistic regression v·ªõi to√°n t·ª≠ XOR

Ph·∫ßn n√†y kh√¥ng b·∫Øt bu·ªôc, n√≥ gi√∫p gi·∫£i th√≠ch vi·ªác c√≥ nhi·ªÅu layer h∆°n th√¨ m√¥ h√¨nh s·∫Ω gi·∫£i quy·∫øt ƒë∆∞·ª£c c√°c b√†i to√°n ph·ª©c t·∫°p h∆°n. C·ª• th·ªÉ l√† m√¥ h√¨nh logistic regression b√†i tr∆∞·ªõc kh√¥ng bi·ªÉu di·ªÖn ƒë∆∞·ª£c to√°n t·ª≠ XOR nh∆∞ng n·∫øu th√™m 1 hidden layer v·ªõi 2 node ·ªü gi·ªØa input layer v√† output layer th√¨ c√≥ th·ªÉ bi·ªÉu di·ªÖn ƒë∆∞·ª£c to√°n t·ª≠ XOR.

AND, OR, XOR l√† c√°c ph√©p to√°n th·ª±c hi·ªán ph√©p t√≠nh tr√™n bit. Th·∫ø bit l√† g√¨? b·∫°n kh√¥ng c·∫ßn quan t√¢m, ch·ªâ c·∫ßn bi·∫øt m·ªói bit nh·∫≠n 1 trong 2 gi√° tr·ªã l√† 0 ho·∫∑c 1.

## NOT

Ph√©p t√≠nh NOT c·ªßa 1 bit cho ra gi√° tr·ªã ng∆∞·ª£c l·∫°i.

## AND

Ph√©p t√≠nh AND c·ªßa 2 bit cho gi√° tr·ªã 1 n·∫øu c·∫£ 2 bit b·∫±ng 1 v√† cho gi√° tr·ªã b·∫±ng 0 trong c√°c tr∆∞·ªùng h·ª£p c√≤n l·∫°i. B·∫£ng ch√¢n l√Ω

## OR

Ph√©p t√≠nh OR c·ªßa 2 bit cho gi√° tr·ªã 1 n·∫øu 1 trong 2 bit b·∫±ng 1 v√† cho gi√° tr·ªã b·∫±ng 0 trong c√°c tr∆∞·ªùng h·ª£p c√≤n l·∫°i. B·∫£ng ch√¢n l√Ω

| 1 | 0 | 1 |
| --- | --- | --- |
| 1 | 1 | 1 |

| A | B | A XOR B |
| --- | --- | --- |
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 0 |

| A | B | A XOR B | A AND B | NOT
(A AND B) | A OR B | (NOT(A AND B)
AND (A OR B)) |
| --- | --- | --- | --- | --- | --- | --- |
| 0 | 0 | 0 | 0 | 1 | 0 | 0 |

## XOR

Ph√©p t√≠nh XOR c·ªßa 2 bit cho gi√° tr·ªã 1 n·∫øu ƒë√∫ng 1 trong 2 bit b·∫±ng 1 v√† cho gi√° tr·ªã b·∫±ng

# trong c√°c tr∆∞·ªùng h·ª£p c√≤n l·∫°i. B·∫£ng ch√¢n l√Ω

Khi thi·∫øt l·∫≠p b√†i to√°n logistic regression, ta c√≥ ƒë·ªì th·ªã

R√µ r√†ng l√† kh√¥ng th·ªÉ d√πng m·ªôt ƒë∆∞·ªùng th·∫≥ng ƒë·ªÉ ph√¢n chia d·ªØ li·ªáu th√†nh 2 mi·ªÅn. N√™n khi b·∫°n d√πng gradient descent v√†o b√†i to√°n XOR th√¨ b·∫•t k·ªÉ b·∫°n ch·∫°y b∆∞·ªõc 2 bao nhi√™u l·∫ßn hay ch·ªânh learning_rate th·∫ø n√†o th√¨ v·∫´n kh√¥ng ra ƒë∆∞·ª£c k·∫øt qu·∫£ nh∆∞ mong mu·ªën. Logistic regression nh∆∞ b√†i tr∆∞·ªõc kh√¥ng th·ªÉ gi·∫£i quy·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ n√†y, gi·ªù c·∫ßn m·ªôt gi·∫£i ph√°p m·ªõi !!!

√Åp d·ª•ng c√°c ki·∫øn th·ª©c v·ªÅ bit ·ªü tr√™n l·∫°i, ta c√≥:

NOT (A AND B)

(NOT(A AND B)

AND (A OR B))

![]({"images/image7.png"})

| 0 | 1 | 1 | 0 | 1 | 1 | 1 |
| --- | --- | --- | --- | --- | --- | --- |
| 1 | 0 | 1 | 0 | 1 | 1 | 1 |
| 1 | 1 | 0 | 1 | 0 | 1 | 0 |

Do ƒë√≥: A XOR B = (NOT(A AND B) AND (A OR B)), v·∫≠y ƒë·ªÉ t√≠nh ƒë∆∞·ª£c XOR ta k·∫øt h·ª£p NOT(AND) v√† OR sau ƒë√≥ t√≠nh ph√©p t√≠nh AND.

![]({"images/image8.png"})

H√¨nh 5.12: M√¥ h√¨nh XOR

Nh√¨n c√≥ v·∫ª r·ªëi nh·ªâ, c√πng ph√¢n t√≠ch nh√©:

node NOT(_x_1 AND _x_2) ch√≠nh l√† t·ª´ h√¨nh 5.10, v·ªõi 3 m≈©i t√™n ch·ªâ ƒë·∫øn t·ª´ 1_,x_1_,x_2 v·ªõi h·ªá s·ªë _w_0_,w_1_,w_2 t∆∞∆°ng ·ª©ng l√† 1.5, -1, -1.

node t√≠nh _x_1 OR _x_2 l√† t·ª´ h√¨nh 5.11

node trong output layer l√† ph√©p t√≠nh AND t·ª´ 2 node c·ªßa layer tr∆∞·ªõc, gi√° tr·ªã h·ªá s·ªë t·ª´ h√¨nh

# mang xu·ªëng.

Nh·∫≠n x√©t: m√¥ h√¨nh logistic regression kh√¥ng gi·∫£i quy·∫øt ƒë∆∞·ª£c b√†i to√°n XOR nh∆∞ng m√¥ h√¨nh m·ªõi th√¨ gi·∫£i quy·∫øt ƒë∆∞·ª£c b√†i to√°n XOR. ƒê√¢u l√† s·ª± kh√°c nhau:

Logistic regression ch·ªâ c√≥ input layer v√† output layer

M√¥ h√¨nh m·ªõi c√≥ 1 hidden layer c√≥ 2 node ·ªü gi·ªØa input layer v√† output layer.

C√†ng nhi·ªÅu layer v√† node th√¨ c√†ng gi·∫£i quy·∫øt ƒë∆∞·ª£c c√°c b√†i to√°n ph·ª©c t·∫°p h∆°n.
